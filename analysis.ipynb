{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0c924d8",
   "metadata": {},
   "source": [
    "# Project Portfolio Analysis\n",
    "\n",
    "This notebook provides an exploratory analysis and predictive modeling exercise on a synthetic project portfolio dataset. \n",
    "\n",
    "The dataset contains information about various projects, including their type, budget, duration, team size, complexity, risk level, stakeholder engagement, and historical success rate. The goal of this analysis is to perform exploratory data analysis (EDA) and build predictive models to estimate the likelihood of project success. This notebook is structured as follows:\n",
    "\n",
    "1. Data loading and overview\n",
    "2. Exploratory Data Analysis (EDA)\n",
    "3. Data preprocessing\n",
    "4. Predictive modeling (Logistic Regression and Random Forest)\n",
    "5. Model evaluation and comparison\n",
    "\n",
    "Feel free to run the cells and explore the dataset and models further!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f99f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Set plot style\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2341c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'project_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12455990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Overview\n",
    "\n",
    "# Display summary statistics\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311c6796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of numerical features\n",
    "numeric_cols = ['budget_kUSD', 'duration_months', 'team_size', 'complexity', 'risk_level', 'stakeholder_engagement', 'prev_success_rate']\n",
    "\n",
    "data[numeric_cols].hist(bins=20, figsize=(12, 10))\n",
    "plt.suptitle('Distribution of Numerical Features', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc6b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix\n",
    "corr = data[['budget_kUSD','duration_months','team_size','complexity','risk_level','stakeholder_engagement','prev_success_rate','project_success']].corr()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c59c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature matrix and target vector\n",
    "X = data.drop(columns=['project_id', 'project_success'])\n",
    "# One-hot encode categorical variable 'project_type'\n",
    "X = pd.get_dummies(X, columns=['project_type'], drop_first=True)\n",
    "y = data['project_success']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "numeric_features = ['budget_kUSD','duration_months','team_size','complexity','risk_level','stakeholder_engagement','prev_success_rate']\n",
    "X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])\n",
    "X_test[numeric_features] = scaler.transform(X_test[numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc229013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_log = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "acc_log = accuracy_score(y_test, y_pred_log)\n",
    "print(f\"Logistic Regression Accuracy: {acc_log:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_log))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_log = confusion_matrix(y_test, y_pred_log)\n",
    "sns.heatmap(cm_log, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Logistic Regression Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374be006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest model\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy: {acc_rf:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens')\n",
    "plt.title('Random Forest Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Feature importance plot\n",
    "importances = pd.Series(rf_clf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "importances.head(15).plot(kind='bar')\n",
    "plt.title('Top Feature Importances (Random Forest)')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance Score')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cf73cb",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates a full workflow for analyzing a synthetic project portfolio dataset. Through EDA, we explored the distributions and correlations of features that may influence project success. We then built two predictive models: Logistic Regression and Random Forest. \n",
    "\n",
    "The Random Forest model generally performed better due to its ability to capture non-linear relationships and interactions among variables. This project can be expanded further by experimenting with additional models, performing hyperparameter tuning, or incorporating new synthetic data features such as time-series metrics or resource allocation details. This analysis provides a solid foundation for business analysts and data enthusiasts looking to practice data-driven decision making and predictive modeling.\n",
    "\n",
    "Feel free to modify, extend, and refine this analysis to suit your needs!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
